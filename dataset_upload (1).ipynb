{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to creating and editing Datasets in the LangSmith UI, you can also create and edit datasets with the LangSmith SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead an upload a list of examples that we have from our RAG application to LangSmith as a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith Key Set: True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  \n",
    "\n",
    "import os\n",
    "print(\"LangSmith Key Set:\", os.getenv(\"LANGCHAIN_API_KEY\") is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['665d4c91-f8e5-46be-8e22-f4f8b9c9b89a',\n",
       "  'a63005ce-9dc9-4581-bb48-6f1de0945132',\n",
       "  '71f26c5c-4f65-46c3-9127-183a225b578d',\n",
       "  '7387e305-7bac-4704-a750-4a52d537e6ff',\n",
       "  '6231eb50-8c19-4c4b-9028-a6e332475df0',\n",
       "  'd3f006fa-1d6f-4dbb-9466-374c0dce1575',\n",
       "  'ca7c18b7-15d6-45fa-96cf-b2cbb06c98d9',\n",
       "  '1c60e230-8082-41bc-be79-48261ee61a7a',\n",
       "  '758a3f88-0656-4b04-a64b-fbbb1d32ca69',\n",
       "  'fb2c22f9-eebf-4f5d-a945-bf90e6e30b2e'],\n",
       " 'count': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "example_inputs = [\n",
    "    (\n",
    "        \"What is Retrieval-Augmented Generation (RAG)?\",\n",
    "        \"RAG is a technique that combines information retrieval with generative models. It retrieves relevant documents from a knowledge base and uses them to ground the model’s response, improving factual accuracy.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Why is RAG preferred over vanilla LLM responses?\",\n",
    "        \"RAG helps improve factual correctness and reduces hallucinations by incorporating external context. It also enables real-time updates without the need to retrain the model.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What are the main components of a RAG pipeline?\",\n",
    "        \"A typical RAG pipeline includes a retriever, a chunked document store (vector DB), and a language model that generates answers using the retrieved documents as context.\"\n",
    "    ),\n",
    "    (\n",
    "        \"How do you choose the right chunk size for a RAG pipeline?\",\n",
    "        \"Chunk size should balance context completeness and token limits. Smaller chunks may miss important context, while larger ones can exceed token limits or dilute relevance.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Can I use RAG with proprietary documents?\",\n",
    "        \"Yes, RAG is ideal for using proprietary or internal documents. You index them in a vector database and retrieve them at query time without exposing data to the base model.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What vector stores are commonly used in RAG?\",\n",
    "        \"Common vector stores include FAISS, Pinecone, Weaviate, Chroma, Qdrant, and even lightweight ones like SKLearnVectorStore for local setups.\"\n",
    "    ),\n",
    "    (\n",
    "        \"How does document retrieval affect RAG accuracy?\",\n",
    "        \"If retrieval fails to return relevant documents, the generation step will likely produce incorrect or vague responses. Retrieval quality is crucial for RAG effectiveness.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Is it possible to use hybrid search in a RAG system?\",\n",
    "        \"Yes, hybrid search combines dense vector search with keyword-based techniques like BM25 to improve recall, especially in noisy or long-text domains.\"\n",
    "    ),\n",
    "    (\n",
    "        \"How can LangSmith help debug a RAG pipeline?\",\n",
    "        \"LangSmith lets you trace each RAG step — retrieval, document context, and model output — so you can inspect failures, measure latency, and iterate effectively.\"\n",
    "    ),\n",
    "    (\n",
    "        \"How do I evaluate the performance of a RAG system?\",\n",
    "        \"You can evaluate RAG systems using metrics like answer correctness, retrieval precision, or reference comparison with datasets. LangSmith supports custom evaluations for this purpose.\"\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "client = Client()\n",
    "from config import DATASET_ID\n",
    "\n",
    "\n",
    "# Prepare inputs and outputs for bulk creation\n",
    "inputs = [{\"question\": input_prompt} for input_prompt, _ in example_inputs]\n",
    "outputs = [{\"output\": output_answer} for _, output_answer in example_inputs]\n",
    "\n",
    "client.create_examples(\n",
    "  inputs=inputs,\n",
    "  outputs=outputs,\n",
    "  dataset_id=dataset_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting another Trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've moved our RAG application definition to `app.py` so we can quickly import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app import langsmith_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask another question to create a new trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RAG stands for Retrieval-Augmented Generation, a technique that combines retrieval and generation to answer questions. It involves indexing and retrieving relevant documents based on a user's question, and then using a language model to generate an answer. This approach is used in the provided code to build a chatbot that answers questions about Lilian Weng's blog posts.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is RAG?\"\n",
    "langsmith_rag(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
